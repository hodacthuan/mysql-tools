#!/bin/sh

#
# This file is released under the terms of the Artistic License.
# Please see the file LICENSE, included in this package, for details.
#
# Copyright (C) 2002 Mark Wong & Open Source Development Lab, Inc.
#

abs_top_srcdir=@abs_top_srcdir@
DBDIR=@database_to_use@

trap 'echo "Test was interrupted by Control-C."; \
	killall client; killall driver; killall sar; killall sadc; killall vmstat; killall iostat; $abs_top_srcdir/scripts/${DBDIR}/stop_db.sh' INT
trap 'echo "Test was interrupted. Got TERM signal."; \
	killall client; killall driver;  killall sar; killall sadc; killall vmstat; killall iostat; $abs_top_srcdir/scripts/${DBDIR}/stop_db.sh' TERM

usage()
{
	if [ "$1" != "" ]; then
		echo
		echo "error: $1"
	fi
}

validate_parameter()
{
	if [ "$2" != "$3" ]; then
		usage "wrong argument '$2' for parameter '-$1'"
		exit 1
	fi
}

do_sleep()
{
    echo "Sleeping $1 seconds"
    sleep $1
}

DB_HOSTNAME="127.0.0.1"
DB_PORT=5432
SLEEPY=1000 # milliseconds
USE_OPROFILE=0
THREADS_PER_WAREHOUSE=10

while getopts "c:d:l:nop:s:t:vw:z:" opt; do
	case $opt in
	c)
		# Check for numeric value
		DBCON=`echo $OPTARG | egrep "^[0-9]+$"`
		validate_parameter $opt $OPTARG $DBCON
		;;
	d)
		DURATION=`echo $OPTARG | egrep "^[0-9]+$"`
		validate_parameter $opt $OPTARG $DURATION
		;;
	l)
		DB_PORT=`echo $OPTARG | egrep "^[0-9]+$"`
		validate_parameter $opt $OPTARG $DB_PORT
		;;
	n)
		NO_THINK="-ktd 0 -ktn 0 -kto 0 -ktp 0 -kts 0 -ttd 0 -ttn 0 -tto 0 -ttp 0 -tts 0"
		;;
	o)
		USE_OPROFILE=1
		;;
	p)
		DB_PARAMS=$OPTARG
		;;
	s)
		SLEEPY=`echo $OPTARG | egrep "^[0-9]+$"`
		validate_parameter $opt $OPTARG $SLEEPY
		;;
	t)
		THREADS_PER_WAREHOUSE=`echo $OPTARG | egrep "^[0-9]+$"`
		validate_parameter $opt $OPTARG $THREADS_PER_WAREHOUSE
		;;
	w)
		WAREHOUSES=`echo $OPTARG | egrep "^[0-9]+$"`
		validate_parameter $opt $OPTARG $WAREHOUSES
		;;
	v)
		set -x
		SHELL="-x"
		;;
	z)
		COMMENT=$OPTARG
		;;
	esac
done

# Check parameters.

if [ "$DBCON" == "" ]; then
	echo "specify the number of database connections using -c #"
	exit 1
fi

if [ "$DURATION" == "" ]; then
	echo "specify the duration of the test in seconds using -t #"
	exit 1
fi

if [ "$WAREHOUSES" == "" ]; then
	echo "specify the number of warehouses using -w #"
	exit 1
fi

if [ $(( $THREADS_PER_WAREHOUSE*1 )) -lt 1 -o $(( $THREADS_PER_WAREHOUSE*1 )) -gt 1000 ]; then
	usage "-t value should be in range [1..1000]. Please specify correct value"
	exit 1
fi

ULIMIT_N=`ulimit -n`
ESTIMATED_ULIMIT=$(( 2*${WAREHOUSES}*${THREADS_PER_WAREHOUSE}+${DBCON} ))
if [ ${ULIMIT_N} -lt $(( $ESTIMATED_ULIMIT )) ]; then
  usage "you're open files ulimit is too small, must be at least ${ESTIMATED_ULIMIT}"
  exit 1
fi

# Determine the output directory for storing data.
RUN_NUMBER=-1
if test -f run_number; then
  read RUN_NUMBER < run_number
fi
if [ $RUN_NUMBER -eq -1 ]; then
	RUN_NUMBER=0
fi
OUTPUT_DIR=output/$RUN_NUMBER
CLIENT_OUTPUT_DIR=$OUTPUT_DIR/client
DRIVER_OUTPUT_DIR=$OUTPUT_DIR/driver
DB_OUTPUT_DIR=$OUTPUT_DIR/db

# Create the directories we will need.
mkdir -p $OUTPUT_DIR
mkdir -p $CLIENT_OUTPUT_DIR
mkdir -p $DRIVER_OUTPUT_DIR
mkdir -p $DB_OUTPUT_DIR

# Update log.html
echo "<a href='$RUN_NUMBER/'>$RUN_NUMBER</a>: $COMMENT<br />" >> output/log.html

# Update the run number for the next test.
RUN_NUMBER=`expr $RUN_NUMBER + 1`
echo $RUN_NUMBER > run_number

# Create a readme file in the output directory and date it.
date >> $OUTPUT_DIR/readme.txt
echo "$COMMENT" >> $OUTPUT_DIR/readme.txt
uname -a >> $OUTPUT_DIR/readme.txt
echo "Command line: $0 $@" >> $OUTPUT_DIR/readme.txt

# Output run information into the readme.txt.
echo "Database Scale Factor: $WAREHOUSES warehouses" >> $OUTPUT_DIR/readme.txt
echo "Test Duration: $DURATION seconds" >> $OUTPUT_DIR/readme.txt
echo "Database Connections: $DBCON" >> $OUTPUT_DIR/readme.txt

$abs_top_srcdir/scripts/${DBDIR}/stop_db.sh
$abs_top_srcdir/scripts/${DBDIR}/start_db.sh -a -p "${DB_PARAMS}"

# Start the client.
echo "Starting client: $DBCON database connection(s), 1 connection per $SLEEPY milliseconds..."
$abs_top_srcdir/src/client -f -d $DB_HOSTNAME -c $DBCON -l $DB_PORT -s $SLEEPY -o $CLIENT_OUTPUT_DIR > $OUTPUT_DIR/client.out 2>&1 &

# Sleep long enough for all the client database connections to be established.
SLEEPYTIME=$(( (1+$DBCON)*$SLEEPY/1000 ))
do_sleep $SLEEPYTIME

# Start collecting data before we start the test.
SLEEP_RAMPUP=$(( (($WAREHOUSES+1)*10*$SLEEPY/1000) ))
SLEEPYTIME=$(( $SLEEP_RAMPUP+$DURATION ))
SAMPLE_LENGTH=60
ITERNATIONS=$(( ($SLEEPYTIME/$SAMPLE_LENGTH)+1 ))
$abs_top_srcdir/scripts/sysstats.sh --iter $ITERNATIONS --sample $SAMPLE_LENGTH --outdir $OUTPUT_DIR > $OUTPUT_DIR/stats.out 2>&1 &
$abs_top_srcdir/scripts/${DBDIR}/db_stat.sh -o $DB_OUTPUT_DIR -i $ITERNATIONS -s $SAMPLE_LENGTH > $OUTPUT_DIR/dbstats.out 2>&1 &

# Initialize oprofile before we start the driver.
if [ $USE_OPROFILE -eq 1 ]
then
        sudo opcontrol --vmlinux=/usr/src/linux-`uname -r`/vmlinux -c 100
        sleep 1
        sudo opcontrol --start-daemon
        sleep 1
        sudo opcontrol --start
fi

DRIVERS=$(( $THREADS_PER_WAREHOUSE*$WAREHOUSES ))
echo "Starting driver: $DRIVERS driver(s), 1 driver starting every $SLEEPY milliseconds..."
$abs_top_srcdir/src/driver -d $DB_HOSTNAME -l $DURATION -wmin 1 -wmax $WAREHOUSES -w $WAREHOUSES -sleep $SLEEPY -outdir $DRIVER_OUTPUT_DIR -tpw $THREADS_PER_WAREHOUSE $NO_THINK > $OUTPUT_DIR/driver.out 2>&1 &
echo "Results will be written to: $OUTPUT_DIR"

do_sleep $SLEEP_RAMPUP

# Clear the readprofile data after the driver ramps up.
if [ -f /proc/profile ]; then
    echo "Clearing profile data"
	sudo /usr/sbin/readprofile -r
fi

# Reset the oprofile counters after the driver ramps up.
if [ $USE_OPROFILE -eq 1 ]
then
    echo "Reseting oprofile counters"    
    sudo opcontrol --reset
fi

# Sleep for the duration of the run.
do_sleep $DURATION

# Collect profile data.
if [ -f /proc/profile ]; then
	PROFILE=$OUTPUT_DIR/readprofile.txt
	/usr/sbin/readprofile -n -m /boot/System.map-`uname -r` > $PROFILE
	cat $PROFILE | sort -n -r -k1 > $OUTPUT_DIR/readprofile_ticks.txt
	cat $PROFILE | sort -n -r -k3 > $OUTPUT_DIR/readprofile_load.txt
fi

# Collect oprofile data.
if [ $USE_OPROFILE -eq 1 ]
then
	sudo opcontrol --dump
	sudo opreport -l -p /lib/modules/`uname -r` -o $OUTPUT_DIR/oprofile.txt
	sudo opreport -l -c -p /lib/modules/`uname -r` -o $OUTPUT_DIR/callgraph.txt
	sudo opcontrol --stop
fi

# Run some post processing analysese.
perl $abs_top_srcdir/scripts/mix_analyzer.pl --infile $DRIVER_OUTPUT_DIR/mix.log --outdir $DRIVER_OUTPUT_DIR > $DRIVER_OUTPUT_DIR/results.out
cp -p notpm.input $DRIVER_OUTPUT_DIR
cd $DRIVER_OUTPUT_DIR
@GNUPLOT@ notpm.input
cd -

if [ $USE_OPROFILE -eq 1 ]
then
	mkdir -p $OUTPUT_DIR/oprofile/
	mkdir -p $OUTPUT_DIR/oprofile/annotate
	cp -pR /var/lib/oprofile/samples/current $OUTPUT_DIR/oprofile/
	sudo opannotate --source --assembly > $OUTPUT_DIR/oprofile/assembly.txt 2>&1
	sudo opannotate --source --output-dir=$OUTPUT_DIR/oprofile/annotate
fi

# Client doesn't go away by itself like the driver does, so kill it.
echo "Killing client..."
killall client driver 2> /dev/null

$abs_top_srcdir/scripts/${DBDIR}/stop_db.sh

# Move the database log.  (No, not the transaction log.)
chmod 644 $abs_top_srcdir/scripts/log
mv $abs_top_srcdir/scripts/log $DB_OUTPUT_DIR

# Postprocessing of Database Statistics
@SAR@ -f ${OUTPUT_DIR}/sar_raw.out -A > ${OUTPUT_DIR}/sar.out
$abs_top_srcdir/scripts/vmplot.sh -i ${OUTPUT_DIR}/vmstat.out \
		-o ${OUTPUT_DIR}/plots
perl $abs_top_srcdir/scripts/${DBDIR}/analyze_stats.pl --dir $DB_OUTPUT_DIR

# Create summary in HTML.
$abs_top_srcdir/scripts/gen_html.sh $OUTPUT_DIR

echo "Test completed."
echo "Results are in: $OUTPUT_DIR"
echo

cat $DRIVER_OUTPUT_DIR/results.out
